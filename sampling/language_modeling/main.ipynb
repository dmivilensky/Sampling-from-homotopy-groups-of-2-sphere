{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "freegroup_dimension = 4\n",
    "\n",
    "path = Path('results', 'language-modeling', f'{freegroup_dimension}-free-group', 'gpt-2', f'{list(range(1, freegroup_dimension + 1))}')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any, Optional, Union\n",
    "from transformers import PretrainedConfig, PreTrainedModel\n",
    "from transformers.utils import ModelOutput\n",
    "from torch import nn, stack\n",
    "import transformers\n",
    "from itertools import repeat\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import TemperatureLogitsWarper, MaxLengthCriteria\n",
    "from torch import full, device\n",
    "from itertools import combinations\n",
    "\n",
    "from freegroup import tools, sampling as smp\n",
    "\n",
    "\n",
    "\n",
    "AggregatedConfig = Tuple[str, Dict[str, Any], bool, bool]\n",
    "\n",
    "def aggregated_config(model_name, model_arguments, from_transformers, from_pretrained):\n",
    "    return (model_name, model_arguments, from_transformers, from_pretrained)\n",
    "\n",
    "def create_aggregated(config: AggregatedConfig):\n",
    "    model_name, model_arguments, from_transformers, from_pretrained = config\n",
    "\n",
    "    model_class = getattr(transformers, model_name) if from_transformers else globals()[model_name]\n",
    "            \n",
    "    if not from_pretrained:\n",
    "        factory = lambda args: model_class(model_class.config_class(**args))\n",
    "    else:\n",
    "        factory = lambda args: model_class.from_pretrained(**args)\n",
    "    \n",
    "    return factory(model_arguments)\n",
    "\n",
    "\n",
    "class EnsembleConfig(PretrainedConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        ensemblee_configs: Optional[List[AggregatedConfig]] = None,\n",
    "        ensemblee_weights: Optional[List[float]] = None,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ensemblee_configs = ensemblee_configs \n",
    "        self.ensemblee_weights = ensemblee_weights\n",
    "\n",
    "\n",
    "class EnsembleModel(PreTrainedModel):\n",
    "    config_class = EnsembleConfig\n",
    "\n",
    "    def __init__(self, config: EnsembleConfig, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "\n",
    "        self.models = nn.ModuleList()\n",
    "        for aggreagted_config in config.ensemblee_configs:\n",
    "            self.models.append(create_aggregated(aggreagted_config))\n",
    "\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = {}\n",
    "        for m in self.models:\n",
    "            m_output = m(*args, **kwargs)\n",
    "            for k, v in m_output.items():\n",
    "                if not k in output:\n",
    "                    output[k] = []\n",
    "                output[k].append(v)\n",
    "        return ModelOutput(output)\n",
    "\n",
    "\n",
    "class EnsembleModelForCausalLM(EnsembleModel):\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = super().forward(*args, **kwargs)\n",
    "        output['logits'] = stack([l * w for l, w in zip(output['logits'], self.config.ensemblee_weights)]).sum(dim=0)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransistedVocabularyConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self, model: AggregatedConfig, src: Dict[str, int], dst: Dict[str, int],\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = model\n",
    "        self.src = src\n",
    "        self.dst = dst\n",
    "\n",
    "class TransistedVocabularyModel(PreTrainedModel):\n",
    "    config_class = TransistedVocabularyConfig\n",
    "\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config)\n",
    "        self.model = create_aggregated(config.model)\n",
    "\n",
    "        self.register_buffer('transition', torch.zeros((len(config.src), len(config.dst)), dtype=torch.long))\n",
    "        for key in config.src.keys():\n",
    "            if key in config.dst:\n",
    "                self.transition[config.src[key], config.dst[key]] = 1\n",
    "\n",
    "        self.register_buffer('arange', torch.arange(len(config.src), dtype=torch.long))\n",
    "\n",
    "    def forward(self, input_ids, *args, **kwargs):\n",
    "        one_hot_encoded = F.one_hot(input_ids, num_classes = len(self.config.src))\n",
    "        transited = one_hot_encoded @ self.transition\n",
    "        input_ids = (transited * self.arange).sum(dim=-1)\n",
    "        output = self.model(input_ids, *args, **kwargs)\n",
    "        output['logits'] = output['logits'] @ self.transition.T.to(self.dtype)\n",
    "        return output\n",
    "\n",
    "def shifted_config(vocab, fgroup_dimension: int, shift: int):\n",
    "    shifted = deepcopy(vocab)\n",
    "    for gen in range(fgroup_dimension):\n",
    "        original_idx, shifted_idx = gen + 1, (gen - shift) % fgroup_dimension + 1\n",
    "        shifted[str(original_idx)] = vocab[str(shifted_idx)]\n",
    "        shifted[str(-original_idx)] = vocab[str(-shifted_idx)]\n",
    "    return shifted\n",
    "\n",
    "\n",
    "def check_contain(sampled, n_generators: int, closures = None):\n",
    "    if closures is None:\n",
    "        closures = {(i,) : set() for i in range(1, n_generators + 1)}\n",
    "        closures.update({tuple(range(1, n_generators + 1)) : set()})\n",
    "\n",
    "    for word in sampled:\n",
    "        for b, s in closures.items():\n",
    "            if tools.is_from_singleton_normal_closure(list(b), word):\n",
    "                s.add(tuple(word))\n",
    "    return closures\n",
    "\n",
    "\n",
    "def sampler(model, tokenizer, batch_size=100, tau=0.5, max_length=100):\n",
    "    def new_batch():\n",
    "        outputs = model.sample(\n",
    "            full((batch_size, 1), tokenizer.bos_token_id).to(model.device),\n",
    "            logits_processor = TemperatureLogitsWarper(tau),\n",
    "            stopping_criteria = MaxLengthCriteria(max_length),\n",
    "            pad_token_id = tokenizer.eos_token_id,\n",
    "            eos_token_id = tokenizer.eos_token_id,\n",
    "        )\n",
    "        outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return list(map(lambda x: list(map(int, x.split())), outputs))\n",
    "    \n",
    "    return smp.iterable_from_batches(new_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freegroup import tools, sampling as smp\n",
    "from itertools import repeat\n",
    "\n",
    "min_length = 0\n",
    "max_length = 100\n",
    "max_depth = 20\n",
    "\n",
    "g = smp.normal_closure(\n",
    "    list(range(1, freegroup_dimension + 1)),\n",
    "    freegroup_dimension,\n",
    "    'brackets',\n",
    "    max_depth = max_depth,\n",
    ")\n",
    "\n",
    "g = map(tools.normalize, g)\n",
    "g = filter(lambda x: len(x) > min_length and len(x) < max_length, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freegroup import tools, sampling as smp\n",
    "from itertools import repeat\n",
    "\n",
    "min_length = 0\n",
    "max_length = 200\n",
    "max_depth = 10\n",
    "n_multipliers = 3\n",
    "\n",
    "generators = [[i] for i in range(1, freegroup_dimension + 1)]\n",
    "g = smp.symmetric_commutant(\n",
    "    generators,\n",
    "    freegroup_dimension,\n",
    "    n_multipliers,\n",
    "    'brackets',\n",
    "    max_depth = max_depth,\n",
    ")\n",
    "\n",
    "g = smp.join(*repeat(g, n_multipliers))\n",
    "g = smp.subset(g)\n",
    "g = smp.reduce(tools.multiply, g)\n",
    "\n",
    "g = map(tools.normalize, g)\n",
    "g = filter(lambda x: len(x) > min_length and len(x) < max_length, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 17.,  57.,  99., 135., 123., 132., 101.,  96., 121., 119.]),\n",
       " array([ 22. ,  39.6,  57.2,  74.8,  92.4, 110. , 127.6, 145.2, 162.8,\n",
       "        180.4, 198. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sampled = list(smp.take_unique(1000, g, verbose=True))\n",
    "plt.hist(list(map(len, sampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110000/110000 [00:53<00:00, 2039.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_size, eval_size = int(10 ** 5), int(10 ** 4)\n",
    "\n",
    "dataset = list(smp.take_unique(train_size + eval_size, g, verbose=True))\n",
    "train_dataset, eval_dataset = dataset[:train_size], dataset[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "prefix = '0-100-20'\n",
    "\n",
    "train_dataset = list(map(str, train_dataset))\n",
    "eval_dataset = list(map(str, eval_dataset))\n",
    "\n",
    "(path / prefix).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(path / prefix / 'train_dataset.pkl', 'wb') as f:\n",
    "    dump(train_dataset, f)\n",
    "\n",
    "with open(path / prefix / 'eval_dataset.pkl', 'wb') as f:\n",
    "    dump(eval_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers import (\n",
    "    normalizers, pre_tokenizers, models, processors, trainers\n",
    ")\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "tokenizer = Tokenizer(models.WordLevel(\n",
    "    vocab = {str(x): i for i, x in enumerate(chain(range(-freegroup_dimension, 0), range(1, freegroup_dimension + 1)))}\n",
    "))\n",
    "tokenizer.add_special_tokens(['[BOS]', '[EOS]'])\n",
    "tokenizer.normalizer = normalizers.Sequence([\n",
    "    normalizers.Replace(\"[\", \"\"),\n",
    "    normalizers.Replace(\"]\", \"\"),\n",
    "])\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
    "    pre_tokenizers.CharDelimiterSplit(','),\n",
    "    pre_tokenizers.WhitespaceSplit(),\n",
    "])\n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[BOS] $ [EOS]\",\n",
    "    special_tokens=[\n",
    "        (\"[BOS]\", tokenizer.token_to_id('[BOS]')),\n",
    "        (\"[EOS]\", tokenizer.token_to_id('[EOS]')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tokenizer.save(str(path / 'tokenizer.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from pickle import load\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=str(path / 'tokenizer.json'), pad_token='[PAD]', bos_token='[BOS]', eos_token='[EOS]')\n",
    "\n",
    "prefix = '0-100-20'\n",
    "\n",
    "with open(path / prefix / 'train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = load(f)\n",
    "\n",
    "with open(path / prefix / 'eval_dataset.pkl', 'rb') as f:\n",
    "    eval_dataset = load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenizer(train_dataset)['input_ids']\n",
    "eval_dataset = tokenizer(eval_dataset)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size  = len(tokenizer.vocab),\n",
    "    n_embd      = 128,\n",
    "    n_layer     = 12,\n",
    "    n_head      = 8,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(str(path / 'checkpoint-15500'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from freegroup import tools, sampling as smp\n",
    "\n",
    "\n",
    "class TrainerWithSampling(Trainer):\n",
    "    def evaluation_loop(self, dataloader, description: str, prediction_loss_only = None, ignore_keys = None, metric_key_prefix: str = \"eval\"):\n",
    "        output = super().evaluation_loop(dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        g = sampler(\n",
    "            self.model,\n",
    "            self.tokenizer,\n",
    "            self.args.eval_sampling_batch_size,\n",
    "            self.args.eval_sampling_tau,\n",
    "            self.args.eval_sampling_max_length,\n",
    "        )\n",
    "        g = map(tools.normalize, g)\n",
    "        g = smp.take_unique(200, g)\n",
    "        g = smp.prefixes(g)\n",
    "        \n",
    "        container = check_contain(list(g), freegroup_dimension)\n",
    "        for l in range(1, len(container.keys()) + 1):\n",
    "            for subset in combinations(container.keys(), l):\n",
    "                output.metrics[f'{metric_key_prefix}_' + '_'.join(map(str, subset))] = len(set.intersection(*[container[s] for s in subset]))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir                  = str(path / prefix),\n",
    "    evaluation_strategy         = 'epoch',\n",
    "    learning_rate               = 5e-3,\n",
    "    weight_decay                = 0.001,\n",
    "    per_device_train_batch_size = 128,\n",
    "    num_train_epochs            = 200,\n",
    "    save_total_limit            = 10,\n",
    ")\n",
    "\n",
    "object.__setattr__(args, 'eval_sampling_batch_size', 100)\n",
    "object.__setattr__(args, 'eval_sampling_tau', 0.5)\n",
    "object.__setattr__(args, 'eval_sampling_max_length', 100)\n",
    "\n",
    "trainer = TrainerWithSampling(\n",
    "    model           = model,\n",
    "    tokenizer       = tokenizer,\n",
    "    args            = args,\n",
    "    train_dataset   = train_dataset, \n",
    "    eval_dataset    = eval_dataset,\n",
    "    data_collator   = data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from torch import cuda\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path('results', 'language-modeling', '4-free-group', 'gpt-2')\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file = str(base_path / '[[1, 2, 3, 4]]' / 'tokenizer.json'), pad_token='[PAD]', bos_token='[BOS]', eos_token='[EOS]')\n",
    "\n",
    "\n",
    "config = EnsembleConfig(\n",
    "    [\n",
    "        aggregated_config(\n",
    "            model_name          = 'GPT2LMHeadModel',\n",
    "            model_arguments     = {'pretrained_model_name_or_path': str(base_path / '[[1, 2, 3, 4]]' / 'long' / 'checkpoint-7500')},\n",
    "            from_transformers   = True,\n",
    "            from_pretrained     = True,\n",
    "        ),\n",
    "        aggregated_config(\n",
    "            model_name          = 'GPT2LMHeadModel',\n",
    "            model_arguments     = {'pretrained_model_name_or_path': str(base_path / '[1, 2, 3, 4]' / '0-100-20' / 'checkpoint-3500')},\n",
    "            from_transformers   = True,\n",
    "            from_pretrained     = True,\n",
    "        ),\n",
    "    ],\n",
    "    [1., 1.],\n",
    ")\n",
    "model = EnsembleModelForCausalLM(config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freegroup import sampling as smp, tools\n",
    "\n",
    "weight, tau = 0.8, 0.55\n",
    "\n",
    "model.config.ensemblee_weights[-1] = weight\n",
    "g = sampler(model, tokenizer, tau = tau, batch_size=50, max_length=100)\n",
    "g = map(tools.normalize, g)\n",
    "g = smp.prefixes(g)\n",
    "\n",
    "def condition(x):\n",
    "    for b in [[1], [2], [3], [4], [1, 2, 3, 4]]:\n",
    "        if not tools.is_from_singleton_normal_closure(b, x):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "g = filter(condition, g)\n",
    "\n",
    "sampled = []\n",
    "for w in smp.take_unique(1000, g, verbose=True):\n",
    "    sampled.append(w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
