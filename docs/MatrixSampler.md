Алгоритм генерирования слов из пересечения нормальных замыканий посредством представлений Санова и оптимизации функции расстояния до единицы состоит в следующем. Пусть имеется слово $v_1 v_2 \dots$, подлежащее проверке на принадлежность нормальному замыканию, где $v_i$ — образующая ($x_1$, $x_2$, ...) в степени 1 или -1 или нейтральный элемент $e$, $i = 1,...,l$, а $l$ — заданная максимальная длина слова. Сначала мы опишем вычисление функции расстояния до единицы при некоторой подстановке в слове. Отсюда будет ясно, как осуществить подстановку типа $x_j \to e$ (или $x_1 \to x_n^{-1}\dots x_2^{-1}$, в случае нормального замыкания типа $\langle x_1 x_2 \dots x_n \rangle$) в слове, чтобы нулевое значение функции отвечало словам, лежащим в соответствующем нормальном замыкании. Затем, мы наконец опишем алгоритм оптимизации этой функции с некоторым аналогичного вида штрафом на "вырожденность" слова.

Итак, вычисление функции расстояния до единицы состоит из нескольких этапов:
1. Вложение слова в $\{0, 1\}^{l\times(2n+1)} \subset \mathbb{R}^{l\times(2n+1)}$ one-hot кодированием букв.
2. Осуществление (при необходимости) подстановок.
3. Замена one-hot кодов букв представлениями Санова.
4. Последовательное умножение матричного представления первой буквы на матричное представление $i$-й буквы с записью результата на место представления первой буквы, для всех $i=2,...,l$.
5. Взятие результата перемножения всех представлений на месте представления первой буквы и сравнение его с единичной матрицей. Результатом вычисления является квадрат $\|\cdot\|_{2,1}$ нормы разности произведения и единичной матрицы.

Мы увидим, что описанная функция является полилинейной. Опишем каждый из шагов более детально:

1. Сначала, слово вкладывается в вещественное пространство, чтобы можно было рассматривать оптимизацию по словам как непрерывную задачу. Для этого мы применяем one-hot кодирование каждой из букв слова. Если длина слова $< l$, мы дополняем его до длины $l$ буквами, обозначающими нейтральный элемент $e$. Представление букв будем выбирать в $\mathbb{R}^{2n + 1}$, под $e_i$, $i=1,...,2n+1$ будем понимать $i$-й орт указанного пространства. Нейтральному элементу поставим в соответствие $e_1$, тем $v_i$, степень которых есть $1$, а основание есть $j$-ая образующая $x_j$, поставим в соответствие $e_{j+1}$, а тем $v_i$, степень которых есть $-1$, а основание есть $x_j$, поставим в соответствие $e_{n+j+1}$. Будем рассматривать представления букв слова как строки матрицы с $l$ строками, которая и будет составлять искомое представление всего слова. Таким образом, пространство, в которое вкладываются слова и по которому осуществляется оптимизация, есть $\mathbb{R}^{l\times(2n+1)}$.
2. Следующим шагом осуществляются простые подстановки, если они предусмотрены (например, если нужно вычислить не просто расстояние до единицы, а таковое после применения подстановки в слове). Подстановка может быть реализована линейной операцией и представлена умножением представления слова на некоторую матрицу справа. Допустим, наша простая подстановка есть $x_j \to e$. Интуитивно понятно, что представление слова под действием этой подстановки изменится так, что строки, равные $e_{j+1}$ или $e_{n+j+1}$ перейдут в $e_1$. Матрицу, осуществляющую эту замену, нетрудно выписать. Домножим на неё справа представление слова с предыдущего шага. Таким образом мы можем "выбросить" образующую $x_j$ из слова, что является первым шагом проверки на принадлежность слова $\langle x_j \rangle$.
3. Далее, мы заменяем представление каждой буквы (каждую строчку в представлении слова) на её представление в некоторой модели гиперболического пространства. Мы используем представление, основанное на представлении Санова. А именно, имея представление Санова для свободной группы на двух образующих $x$ и $y$, положим представление $x_j$, $j=1,...,n$ равным представлению Санова коммутатора $[x, y^j]$. Это представление будет лежать в $\mathbb{R}^{2\times 2}$. Для удобства применив очевидную биекцию в $\mathbb{R}^4$, получим новый вид строки, прежде равной $e_{j+1}$, в представлении слова. Чтобы получить новый вид строки $e_{n+j+1}$, возьмём представление Санова коммутатора $[x, y^j]$ и обратим его как матрицу, так же отобразив в $\mathbb{R}^4$. Новым видом строки $e_1$ положим результат того же отображения в $\mathbb{R}^4$ единичной матрицы в $\mathbb{2\times 2}$ (соответствующей представлению Санова нейтрального элемента). Итак, для строки любого вида в представлении слова из предыдущего шага мы имеем новый желаемый вид. Переход к новому виду эквивалентен некоторому линейному отображению $\mathbb{R}^{l\times(2n+1)} \to \mathbb{R}^{l\times 4}$. Представим его матрицей и домножим представление слова с предыдущего шага на неё справа. Заметим, что до текущего шага матрицы линейных отображений зависили лишь от $n$ и $l$, но никак не от слова, а значит до сего момента результат вычисления линейно зависит от входа.
4. На этом шаге, мы вычисляем произведение представлений каждой из $l$ букв слова как матриц, вычисляя таким образом представление Санова всего слова. Построим процедуру умножения так: сначала перемножим первое представление и второе, записав результат на место первого; затем перемножим этот результат на первом месте с третьим представлением, результат снова запишем на место первого и так далее. Таким образом, нам достаточно описать процедуру умножения первого представления с $i$-м, $i=2,...,l$. Заметим, что операция умножения матриц билинейна по элементам этих матриц, а значит может быть представлена некоторым тензором соответствующей билинейной формы. Немного потрудившись, можно выписать этот $\mathbb{R}^{4\times 4\times 4}$ тензор для перемножения двух $\mathbb{R}^4$ представлений букв как матриц. Далее осуществим несколько избыточные операции, которые можно было бы заменить на взятие первой и $i$-той строк из представления слова с предыдущего шага, их домножение слева и справа на тензор и запись результата на место первой строки, но необходимые для того, чтобы функция оставалась в явном виде представлена как композиция линейных и билинейных отображений в стандартной форме (умножением на матрицу/тензор), без неясных с математической точки зрения, но естественных при программировании операций типа "взять $i$-тую строку" и "записать на место $i$-той строки". А именно, перемножим представление слова с предыдущего шага слева и справа на тензор и транспонируем. Получим тензор из ($\mathbb{R}^{l\times 4} \times \mathbb{R}^{4\times 4 \times 4} \times \mathbb{R}^{4\times l} \to \mathbb{R}^{l\times 4\times l} \to$) $\mathbb{R}^{l \times l \times 4}$, в каждом элементе которого по первым двум индексам $k$ и $l$ лежит результат умножения $k$-й и $l$-й строки. Домножив полученный тензор справа на матрицу из $\mathbb{R}^{l\times l}$ с единицей на позиции с индексами $1$ и $i$ и нулями в остальных позициях, слева на матрицу из $\mathbb{R}^{l\times l}$ с единицей на позиции с индексами $1$ и $1$ и нулями в остальных позициях и ещё слева на вектор из $\mathbb{R}^l$ c единицей на первой позиции и нулями в остальных позициях, получим матрицу, нужный нам результат в которой находится в первой строке. Остаётся только домножить представление слова с предыдущей итерации слева на матрицу, обнуляющую первую строку, и сложить с результатом, заменив таким образом первую строку на содержащую результат.
5. Проитерировав предыдущий шаг по $i=2,...,l$ и домножив результат слева на уже упоминавшийся вектор из $\mathbb{R}^l$ c единицей на первой позиции и нулями в остальных позициях, получим представление Санова исходного слова. Оно равно "вытянутой в вектор" единичной матрице тогда и только тогда, когда исходное слово после подстановок и нормализации оказывается равным нейтральному элементу. Вычитая из результирующего вектора вектор, соответствующий единичной матрице, и вычисляя квадрат $\|\cdot\|_2$ нормы (что есть также билинейная операция), получаем в некотором роде "расстояние" между исходным словом после подстановок и нейтральным элементам в представлении Санова. Это и есть искомое значение функции на слове. 

Итак, мы располагаем полилинейной функцией $r \prime: \mathbb{R}^{l \times (2n+1)} \to \mathbb{R}$, соответствующей ситуации, когда никаких подстановок не применяется. С точностью до очевидной биекции эта функция эквивалентна $r: \mathbb{R}^{l \cdot (2n+1)} \to \mathbb{R}$. Также пусть $f_j: \mathbb{R}^{l \cdot (2n+1)} \to \mathbb{R}$, $j=1$,...,$n$ обозначают функции, в которых применяется подстановка $x_j \to e$, а $f_{n+1}: \mathbb{R}^{l \cdot (2n+1)} \to \mathbb{R}$ будет функцией с подстановкой $x_1 = x_n^{-1} \dots x_2^{-1}$. 

Задумаемся теперь над тем, с какими представления слов нам приходится оперировать. Изначально мы предполагали, что в нашем распорящении есть one-hot представления слов из $\{0, 1\}^{l \times (2n+1)} \subset \mathbb{R}^{l \times (2n+1)}$. Однако для наших целей важна возможность выходить за пределы дискретного множества $\{0, 1\}^{l \times (2n+1)}$, дабы обеспечить применимость стандартных методов непрерывной оптимизации. Очевидно, наши полилинейные функции $r, f_1, ..., f_{n+1}$ достаточно естественно продолжимы на $\mathbb{R}^{l \times (2n+1)}$ без изменения описанной процедуры вычисления. Однако нам бы не хотелось заставлять алгоритм работать с заведомо неудобными представлениями, едва ли соответствующими каким-либо словам, то есть мы хотели бы передавать на вход нашим функциях представления, вид которых близок к one-hot. Это может быть достигнуто предварительным построчным применением к входному представлению функции $softmax_\beta: \mathbb{R}^{2n+1} \ni y \mapsto \left(e^{\beta y_k} / \sum_{k=1}^{2n+1} e^{\beta y_k}\right)_{k=1}^{2n+1} \in \mathbb{R}^{2n+1}_+$:
$$Softmax_\beta(x) = \begin{pmatrix}softmax_\beta(x_1)\\\vdots\\softmax_\beta(x_l)\end{pmatrix},$$
где $y_k$ для векторов обозначает взятие $k$-того элемента, и $x_i$ для матриц обозначает взятие $i$-той строки.

Положим нашу целевую функцию равной
$$f_{\beta_1, \beta_2, \lambda} (x) = \sum_{j=1}^{n+1} f_j(Softmax_{\beta_1}(x)) + \frac{\lambda}{r(Softmax_{\beta_2}(x))}.$$
Мы полагаем в данном случае вклад каждой из функций $f_j$, $j=1,...,n+1$ равным, чтобы добиться принадлежности слова, представленного $x$, всем нормальным замыканиям $\langle x_1 \rangle, ..., \langle x_n \rangle, \langle x_1 \dots x_n\rangle$. Слагаемое $1/r$ играет здесь роль штрафа на "вырожденность" слова, который при приближении слова к тривальному (равному после нормализации нейтральному элементу) резко возрастает. Разумно выбирать $\beta_2 \gg \beta_1$, чтобы предотвратить накопление большой неточности, порождаемой отхождением входа функции от one-hot вида, при вычислении $r$, что привело бы к резкому уменьшению штрафа. 

Заметим источники и причины нелинейности целевой функции. Во-первых, нелинейность порождается композицией имеющихся  полилинейных функций с существенно нелинейной функцией $Softmax$. При оптимизации она играет роль своего рода штрафа за недискретность входного представления, возможная степень свободы здесь — замена композиции с такого рода функцией слагаемым вида $\mu \sum_{i=1, j=k}^{l, 2n+1} (x_{i,j}-1)^2 x_{i,j}^2$, $\mu > 0$, которое к тому же полилинейно и сепарабельно, и также отталкивает решение от неподходящих значений к дискретным $\{0, 1\}$, однако не отображает строки входного представления в симплекс, что может привести (и скорее всего приведёт) к проблемам типа предпочтения выбора нескольких букв на одну позицию. Во-вторых, источником рациональной нелинейности является штраф $1/r$, разумную альтернативу которому найти достаточно трудно.

Итак, опишем алгоритм оптимизации. Мы используем простейший алгоритм глобальной оптимизации — метод мультистарта с локальным градиентным спуском с клиппингом. Этот алгоритм имеет несколько уровней, каждый из которых далее описывается подробно:

1. На внешнем уровне осуществляется мультистарт, при котором случайно генерируется начальная точка для последующего спуска к локальному минимуму. Мультистарт призван помочь нахождению лучшего (наиболее близкого к глобальному) локального минимума при неспособности алгоритма спуска самого по себе "перескакивать" между локальными минимумами. Нами были опробованы две стратегии случайного мультистарта: генерирование случайного слова длины < $l$ из свободной группы с его последующим представлением one-hot кодом, и генерирование случайной матрицы $[0, 1]^{l\times (2n+1)}$ с н.о.р. элементами из $\mathcal{U}[0, 1]$. Существенно более эффективной стратегией оказывается последняя. Число итераций внешнего уровня определяет число желаемых к получению слов из пересечения нормальных замыканий и не ограниченно. 
2. На внутреннем уровне осуществляется спуск к локальному минимуму посредством любого из градиентных методов. Нами были протестированы стандартный градиентный спуск, AdaGrad, демпфированный метод Ньютона и градиентный спуск с клиппингом. Последний оказался наиболее эффективным, его итерация имеет вид: 
    $$x_{t+1} = x_t - \nabla f_{\beta_1, \beta_2, \lambda}(x_t) / \|\nabla f_{\beta_1, \beta_2, \lambda}(x_t)\|.$$ 
    Число итераций этого уровня ограничивает точность, с которой мы находим локальный минимум функции. Разумно указывать это число большим, полагаясь на условия ранней остановки.
3. Далее указываются используемые условия ранней остановки, призванные как можно уменьшить число итераций градиентного метода, заведомо не приводящих к лучшему решению. Первое условие призвано завершить итерацию внутреннего уровня по достижении побочного локального минимума. Оно имеет вид:
    $$\|\nabla f_{\beta_1, \beta_2, \lambda}(x_t)\| \leq 10^{-80} \wedge \sum_{j=1}^{n+1} f_j(Softmax_{\beta_1}(x)) > c,$$
    где $c > 0$ (у нас $c=1$). Поясним природу этого условия. Будем считать словами, доставляющими побочный локальный минимум, по определению такие слова, в которых градиент равен нулю не в силу малости одновременно градиента нерегуляризованной функции и градиента штрафа, но только потому, что эти градиенты друг друга компенсируют, иначе говоря, движение в сторону минимума по расхождению приводит к пропорциональному росту штрафа. Это эквивалентно близости к вырожденному слову, которому тогда и соответствует локальный минимум уже нерегуляризованной функции, тем не менее не являющийся искомым ответом, а только вырожденным словом. Второе очевидное условие останова состоит в проверке полученного слова на принадлежность всем нормальным замыканиям и факта нетривиальности слова, путём его нормализации. Заметим, что с момента входа на внутренний уровень число итераций до выполнения одного из двух указанных условий для $n < 4$ в подавляющем большинстве случаев не превосходит 50 итераций (при рекомендуемых значениях гиперпараметров). Иными словами, каждая точка, генерируемая мультистартом, за 50 итераций скорее всего либо приведёт к искомому слову (так чаще всего происходит при $n=2$), либо будет обозначена как ведущая к побочному локальному минимуму и отвергнута (случай, наиболее частый уже при $n=3$).

Ради ясности отметим, что везде, где необходимо получить из непрерывного представления $x$ само слово, мы получаем его так: сначала применяем функцию $Softmax_{\beta_1}$, а затем в каждой строчке выбираем максимальный элемент, заменяя его на единицу и обнуляя все прочие элементы. Замечательно, что слова, состоящие из одних лишь нейтральных элементов (при рекомендуемых настройках гиперпараметров) почти никогда не генерируются описанным алгоритмом, слова, состоящие лишь из одного типа букв также довольно редки. Таким образом, введение штрафов на число нейтральных элементов или на однообразие генерируемых букв нецелессобразны (что подтверждается также проверками, которые мы провели на этот счёт).